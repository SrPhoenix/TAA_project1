{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#to load matlab mat files\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"SaYoPillow.csv\")\n",
    "\n",
    "data.head()\n",
    "data.rename(columns = {'sr':'snoring rate', 'rr':'respiration rate',\n",
    "                        't':'body temperature', 'lm':'limb movement', \n",
    "                        'bo':'blood oxygen', 'rem':'eye movement', \n",
    "                        'sr.1':'sleeping hours','hr':'heart rate', \n",
    "                        'sl':'stress level'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snoring rate</th>\n",
       "      <th>respiration rate</th>\n",
       "      <th>body temperature</th>\n",
       "      <th>limb movement</th>\n",
       "      <th>blood oxygen</th>\n",
       "      <th>eye movement</th>\n",
       "      <th>sleeping hours</th>\n",
       "      <th>heart rate</th>\n",
       "      <th>stress level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.00000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>71.600000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>92.80000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>90.900000</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.372833</td>\n",
       "      <td>3.966111</td>\n",
       "      <td>3.52969</td>\n",
       "      <td>4.299629</td>\n",
       "      <td>3.902483</td>\n",
       "      <td>11.893747</td>\n",
       "      <td>3.054572</td>\n",
       "      <td>9.915277</td>\n",
       "      <td>1.415337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>90.50000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>93.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>91.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>98.750000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       snoring rate  respiration rate  body temperature  limb movement  \\\n",
       "count    630.000000        630.000000         630.00000     630.000000   \n",
       "mean      71.600000         21.800000          92.80000      11.700000   \n",
       "std       19.372833          3.966111           3.52969       4.299629   \n",
       "min       45.000000         16.000000          85.00000       4.000000   \n",
       "25%       52.500000         18.500000          90.50000       8.500000   \n",
       "50%       70.000000         21.000000          93.00000      11.000000   \n",
       "75%       91.250000         25.000000          95.50000      15.750000   \n",
       "max      100.000000         30.000000          99.00000      19.000000   \n",
       "\n",
       "       blood oxygen  eye movement  sleeping hours  heart rate  stress level  \n",
       "count    630.000000    630.000000      630.000000  630.000000    630.000000  \n",
       "mean      90.900000     88.500000        3.700000   64.500000      2.000000  \n",
       "std        3.902483     11.893747        3.054572    9.915277      1.415337  \n",
       "min       82.000000     60.000000        0.000000   50.000000      0.000000  \n",
       "25%       88.500000     81.250000        0.500000   56.250000      1.000000  \n",
       "50%       91.000000     90.000000        3.500000   62.500000      2.000000  \n",
       "75%       94.250000     98.750000        6.500000   72.500000      3.000000  \n",
       "max       97.000000    105.000000        9.000000   85.000000      4.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 8)\n",
      "(630, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data.iloc[:, :-1])\n",
    "y = np.array(data.iloc[:, -1]).reshape(len(y),1)\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sigmoid FUNCTION from the previous lab\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    return the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    #gz=np.divide(1,1 + np.exp(-z))\n",
    "    gz=1/(1+np.exp(-z))\n",
    "    return gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add costFunctionReg FUNCTION from the previous lab (the function that computes the regularized cost and the gradients)\n",
    "def costFunctionReg(X, y, theta, Lambda):\n",
    "    \"\"\"\n",
    "    Take in numpy array of  data X, labels y and theta, to return the regularized cost function and gradients\n",
    "    of the logistic regression classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    #number of training examples \n",
    "    m=len(y)\n",
    "        \n",
    "    #vector of the model predictions for all training examples      \n",
    "    h = sigmoid(np.dot(X,theta))\n",
    "    \n",
    "    error = (-y * np.log(h)) - ((1-y)*np.log(1-h))\n",
    "    \n",
    "    #cost function without regularization term\n",
    "    cost = sum(error)/m\n",
    "    \n",
    "    #add regularization term to the cost function L2 norm\n",
    "    regCost= cost + Lambda/(2*m) * sum(theta[1:]**2)\n",
    "    \n",
    "    #gradient of theta_0\n",
    "    grad_0= (1/m) * np.dot(X.transpose(),(h - y))[0]\n",
    "    \n",
    "    #vector of gradients of theta_j from j=1:n (adding the regularization term of the gradient)\n",
    "    grad = (1/m) * np.dot(X.transpose(),(h - y))[1:] + (Lambda/m)* theta[1:]\n",
    "       \n",
    "    # all gradients in a column vector shape\n",
    "    grad_all=np.append(grad_0,grad)\n",
    "    grad_all = grad_all.reshape((len(grad_all), 1))\n",
    "    \n",
    "    return regCost[0], grad_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add gradientDescent FUNCTION from the previous lab (the function that returns the optimal theta vector and J_history)\n",
    "def gradientDescent(X,y,theta,alpha,num_iters,Lambda):\n",
    "    \"\"\"\n",
    "    Take in numpy array X, y and theta and update theta by taking num_iters gradient steps\n",
    "    with learning rate of alpha\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        \n",
    "    return theta and the list of the cost of theta during each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    J_history =[]\n",
    "    for i in range(num_iters):\n",
    "        #call CostFunctionReg \n",
    "        cost, grad = costFunctionReg(X,y,theta,Lambda)\n",
    "        \n",
    "        #update theta\n",
    "        theta = theta-alpha*grad\n",
    "        \n",
    "        J_history.append(cost)\n",
    "    \n",
    "    return theta , J_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def oneVsAll(X, y, initial_theta, alpha, num_iters, Lambda, K):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    numpy array of data X and labels y\n",
    "    initial_theta - inicialized vector of model parameters theta \n",
    "    alpha - learning rate\n",
    "    num_iters - number of iterations\n",
    "    Lambda - regularization parameter \n",
    "    K -number of classes\n",
    "    \n",
    "    ONEVSALL trains K Logistic Regression classifiers using gradient descent. \n",
    "    \n",
    "    Returns:   \n",
    "    all_theta - Kxn matrix where i-th row corresponds to the i-th classifier, n parameters\n",
    "    all_J - the evolution of cost function during each iteration (J_history) for all K classifiers\n",
    "    \n",
    "    \"\"\"\n",
    "    all_theta = []\n",
    "    all_J=[]\n",
    "    \n",
    "    #number of training examples\n",
    "    m=len(y)\n",
    "    \n",
    "    #number of features\n",
    "    n=X.shape[1]\n",
    "    \n",
    "    # add an extra column of 1Â´s corresponding to xo=1 (aka intercept term)\n",
    "    X=np.append(np.ones((m,1)),X,axis=1)\n",
    "    \n",
    "    for i in range(1,K+1):\n",
    "        theta , J_history = gradientDescent(X,np.where(y==i,1,0),initial_theta,alpha,num_iters,Lambda)\n",
    "        \n",
    "        # sdd the vector of optimized parameters theta of classifier i\n",
    "        all_theta.extend(theta)\n",
    "                \n",
    "        # add the cost function history of classifier i\n",
    "        all_J.extend(J_history)\n",
    "        \n",
    "    return np.array(all_theta).reshape(K,n+1), all_J\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23710/281972933.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  gz=1/(1+np.exp(-z))\n",
      "/tmp/ipykernel_23710/3296616311.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  error = (-y * np.log(h)) - ((1-y)*np.log(1-h))\n",
      "/tmp/ipykernel_23710/3296616311.py:14: RuntimeWarning: invalid value encountered in multiply\n",
      "  error = (-y * np.log(h)) - ((1-y)*np.log(1-h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "(10, 9)\n"
     ]
    }
   ],
   "source": [
    "#Inicialize vector theta =0\n",
    "initial_theta = np.zeros((x.shape[1]+1,1))\n",
    "\n",
    "#Optimization hyper-parameters \n",
    "alpha=1 #learning rate\n",
    "num_iters=300\n",
    "Lambda=0.1\n",
    "all_theta, all_J = oneVsAll(x, y, initial_theta, alpha, num_iters, Lambda, 10)\n",
    "print(np.size(all_theta))\n",
    "print(all_theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cost function using Gradient Descent')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(all_J)\n",
    "plt.plot(all_J)  #All classifiers\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"$J(\\Theta)$\")\n",
    "plt.title(\"Cost function using Gradient Descent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
